name: Reusable - Logs Harvest
on:
  workflow_call:
    inputs:
      lookback_runs:
        type: number
        required: false
        default: 20
      persist_branch:
        type: string
        required: false
        default: ''
      advisory_title:
        type: string
        required: false
        default: AI advisory (logs observe)
      advisory_labels_csv:
        type: string
        required: false
        default: ci:advisory
      advisory_topic_key:
        type: string
        required: false
        default: ''
      advisory_daily_budget:
        type: number
        required: false
        default: 1
      advisory_aggregate_title:
        type: string
        required: false
        default: AI Aggregated Logs
permissions:
  actions: read
  contents: write

jobs:
  harvest:
    runs-on: ubuntu-latest
    outputs:
      advisory_body: ${{ steps.format.outputs.body }}
    steps:
      - uses: actions/checkout@v4

      - name: Install GitHub CLI
        uses: cli/cli-action@v2

      - name: Fetch recent workflow runs
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          gh api -H "Accept: application/vnd.github+json" \
            /repos/${{ github.repository }}/actions/runs?per_page=${{ inputs.lookback_runs }} > runs.json

      - name: Download job logs
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          python <<'PY'
          import json, os, pathlib, zipfile, io, urllib.request

          token = os.environ['GH_TOKEN']
          api = os.environ.get('GITHUB_API_URL', 'https://api.github.com')
          repository = os.environ['GITHUB_REPOSITORY']
          headers = {
              'Authorization': f'Bearer {token}',
              'Accept': 'application/vnd.github+json',
          }

          logs_dir = pathlib.Path('.ga/logs')
          logs_dir.mkdir(parents=True, exist_ok=True)

          runs = json.load(open('runs.json')).get('workflow_runs', [])
          for run in runs:
              rid = run['id']
              jobs_url = f"{api}/repos/{repository}/actions/runs/{rid}/jobs"
              with urllib.request.urlopen(urllib.request.Request(jobs_url, headers=headers)) as resp:
                  jobs = json.load(resp).get('jobs', [])
              for job in jobs:
                  jid = job['id']
                  logs_url = f"{api}/repos/{repository}/actions/jobs/{jid}/logs"
                  with urllib.request.urlopen(urllib.request.Request(logs_url, headers=headers)) as resp:
                      data = resp.read()
                  with zipfile.ZipFile(io.BytesIO(data)) as archive:
                      for name in archive.namelist():
                          target = logs_dir / f"run_{rid}_job_{jid}_{name.replace('/', '_')}"
                          target.parent.mkdir(parents=True, exist_ok=True)
                          target.write_bytes(archive.read(name))
          PY

      - name: Parse logs into observability.jsonl
        run: |
          python <<'PY'
          import datetime, glob, json, os, re

          patterns = {
              'error': re.compile(r"\b(error|exception|traceback|fatal)\b", re.I),
              'warn': re.compile(r"\b(warn(ing)?|deprecated)\b", re.I),
              'timeout': re.compile(r"\b(timeout|timed out|deadline)\b", re.I),
              'oom': re.compile(r"\b(outofmemory|enomem|oom)\b", re.I),
              'ratelimit': re.compile(r"\b(rate limit|http 429)\b", re.I),
          }

          os.makedirs('.ga', exist_ok=True)
          rows = []
          timestamp = datetime.datetime.utcnow().isoformat() + 'Z'
          for path in sorted(glob.glob('.ga/logs/*')):
              try:
                  with open(path, 'r', errors='ignore') as handle:
                      text = handle.read()
              except OSError:
                  continue
              signals = {key: bool(pattern.search(text)) for key, pattern in patterns.items()}
              if any(signals.values()):
                  rows.append({'ts': timestamp, 'file': path, 'signals': signals, 'size': len(text)})
          with open('.ga/observability.jsonl', 'w', encoding='utf-8') as handle:
              for row in rows:
                  handle.write(json.dumps(row, ensure_ascii=False) + '\n')
          print(f'rows={len(rows)}')
          PY

      - name: Upload logs artifact
        uses: actions/upload-artifact@v4
        with:
          name: ga-logs
          path: |
            .ga/logs
            .ga/observability.jsonl

      - name: Persist observability branch
        if: ${{ inputs.persist_branch != '' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master') && hashFiles('.ga/observability.jsonl') != '' }}
        run: |
          set -euo pipefail
          git config user.name "github-actions"
          git config user.email "actions@users.noreply.github.com"
          mkdir -p data/ga
          cp -f .ga/observability.jsonl data/ga/observability.jsonl
          git add data/ga/observability.jsonl
          git commit -m "chore(observability): update" || true
          git switch -c "${{ inputs.persist_branch }}" || git switch "${{ inputs.persist_branch }}"
          git push origin HEAD:"${{ inputs.persist_branch }}" --force

      - name: Prepare advisory body
        id: format
        run: |
          if [ ! -s .ga/observability.jsonl ]; then
            echo "body=" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          python <<'PY' > .ga/advisory.md
          from pathlib import Path

          lines = [line.strip() for line in Path('.ga/observability.jsonl').read_text(encoding='utf-8').splitlines() if line.strip()]
          tail = lines[-20:]
          if not tail:
              raise SystemExit(0)
          print('AI観測（助言のみ）：直近ログからのシグナル\n')
          print('```json')
          for entry in tail:
              print(entry)
          print('```')
          PY
          if [ -s .ga/advisory.md ]; then
            {
              echo "body<<EOF"
              cat .ga/advisory.md
              echo "EOF"
            } >> "$GITHUB_OUTPUT"
          else
            echo "body=" >> "$GITHUB_OUTPUT"
          fi

  route:
    needs: harvest
    if: ${{ inputs.advisory_topic_key != '' && needs.harvest.outputs.advisory_body != '' }}
    uses: ./.github/workflows/reusable/issue-router.yml
    with:
      title: ${{ inputs.advisory_title }}
      body: ${{ needs.harvest.outputs.advisory_body }}
      labels_csv: ${{ inputs.advisory_labels_csv }}
      topic_key: ${{ inputs.advisory_topic_key }}
      daily_budget: ${{ inputs.advisory_daily_budget }}
      aggregate_title: ${{ inputs.advisory_aggregate_title }}
